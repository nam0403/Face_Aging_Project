import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
import argparse
import os

# Import cÃ¡c module tá»± viáº¿t
from utils import SiameseWrapper, ContrastiveLoss, CACDPairDataset, train_one_epoch
from models.simple_cnn import SimpleCNNBackbone
from models.facenet_model import FaceNetBackbone
from models.arcface_model import ArcFaceResNetBackbone

# --- Cáº¤U HÃŒNH ---
CONFIG = {
    "data_dir": "data/CACD_Cropped_112", # <--- Sá»¬A ÄÆ¯á»œNG DáºªN Cá»¦A Báº N
    "img_size": 112,
    "embedding_size": 512,
    "batch_size": 32, # TÄƒng lÃªn 64 náº¿u GPU máº¡nh
    "epochs": 20,
    "lr": 0.001,
    "margin": 1.0,
    "pairs_per_epoch": 5000 # Sá»‘ lÆ°á»£ng cáº·p train má»—i epoch
}

def get_model(model_name):
    """Factory function Ä‘á»ƒ láº¥y model dá»±a trÃªn tÃªn"""
    if model_name == 'simple_cnn':
        print("Äang khá»Ÿi táº¡o: Simple CNN")
        backbone = SimpleCNNBackbone(CONFIG['embedding_size'])
    elif model_name == 'facenet':
        print("Äang khá»Ÿi táº¡o: FaceNet (InceptionResnetV1)")
        backbone = FaceNetBackbone(CONFIG['embedding_size'])
    elif model_name == 'arcface':
        print("Äang khá»Ÿi táº¡o: ArcFace (ResNet50)")
        backbone = ArcFaceResNetBackbone(CONFIG['embedding_size'])
    else:
        raise ValueError(f"Model {model_name} khÃ´ng há»— trá»£.")
    
    # Bá»c trong Siamese Wrapper
    return SiameseWrapper(backbone)

def main():
    # 1. Parse tham sá»‘ dÃ²ng lá»‡nh
    parser = argparse.ArgumentParser(description="Train Face Recognition Models for Temporal Robustness")
    parser.add_argument('--model', type=str, required=True, choices=['simple_cnn', 'facenet', 'arcface'], 
                        help='Chá»n model Ä‘á»ƒ train: simple_cnn, facenet, hoáº·c arcface')
    parser.add_argument('--subset', type=float, default=0.4, help='Tá»· lá»‡ dá»¯ liá»‡u sá»­ dá»¥ng (0.1 - 1.0)')
    args = parser.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âš™ï¸ Device: {device}")

    # 2. Prepare Data
    train_transform = transforms.Compose([
        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.1, contrast=0.1),
        transforms.ToTensor(),
        transforms.Normalize([0.5]*3, [0.5]*3)
    ])

    print("ðŸ“‚ Äang load Dataset...")
    dataset = CACDPairDataset(
        root_dir=CONFIG['data_dir'],
        transform=train_transform,
        subset_ratio=args.subset,
        num_pairs=CONFIG['pairs_per_epoch']
    )
    
    loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)

    # 3. Prepare Model
    model = get_model(args.model).to(device)

    # 4. Loss & Optimizer
    criterion = ContrastiveLoss(margin=CONFIG['margin'])
    optimizer = optim.Adam(model.parameters(), lr=CONFIG['lr'])
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

    # 5. Training Loop
    print(f"\nðŸš€ Báº®T Äáº¦U TRAIN MODEL: {args.model.upper()}")
    print(f"   - Epochs: {CONFIG['epochs']}")
    print(f"   - Batch size: {CONFIG['batch_size']}")
    
    save_dir = "checkpoints"
    os.makedirs(save_dir, exist_ok=True)

    for epoch in range(CONFIG['epochs']):
        avg_loss = train_one_epoch(model, loader, criterion, optimizer, device, epoch+1)
        
        print(f"âœ¨ Epoch {epoch+1}/{CONFIG['epochs']} - Avg Loss: {avg_loss:.4f}")
        scheduler.step()

        # Save checkpoint
        if (epoch + 1) % 5 == 0:
            save_path = os.path.join(save_dir, f"{args.model}_epoch_{epoch+1}.pth")
            torch.save(model.state_dict(), save_path)
            print(f"ðŸ’¾ ÄÃ£ lÆ°u model: {save_path}")

    print("\nâœ… HUáº¤N LUYá»†N HOÃ€N Táº¤T!")

if __name__ == '__main__':
    main()